{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaMulticore\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load previosly created dataframe\n",
    "df = pd.read_csv('../data/df_final.csv',index_col=0, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle dataframe\n",
    "df = df.sample(frac=1, random_state=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create word mapping and corpus for gensim\n",
    "document_list = list(df['fragment'].apply(lambda x: x[1:-1].replace(\"'\",\"\").split(',')))\n",
    "id2words = corpora.Dictionary(document_list)\n",
    "\n",
    "corpus = []\n",
    "for document in document_list:\n",
    "    new = id2words.doc2bow(document)\n",
    "    corpus.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and test corpus for estimaiton and perplexity calculation\n",
    "train_corpus, test_corpus = train_test_split(corpus, test_size=0.1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create LDA Model with basic params\n",
    "n_topics = [1,5,10,15,20,30,35,40,50]\n",
    "alphas = [0.1,0.01,0.001]\n",
    "betas = [0.01,0.001,0.0001,0.00001] \n",
    "\n",
    "results = []\n",
    "models = []\n",
    "for n_topic in n_topics:\n",
    "    for alpha in alphas:\n",
    "        for beta in betas:\n",
    "            lda_model = LdaMulticore(\n",
    "                corpus=train_corpus,\n",
    "                id2word=id2words,\n",
    "                num_topics=n_topic,\n",
    "                passes=10,\n",
    "                alpha=alpha,\n",
    "                eta=beta,\n",
    "                random_state=1\n",
    "            )\n",
    "            perp = np.exp(-1. * lda_model.log_perplexity(test_corpus))\n",
    "            print(f'model params: alpha:{alpha} beta:{beta} n_topics:{n_topic}')\n",
    "            print(f'model perplexity: {perp}')\n",
    "            results.append(tuple([n_topic, alpha, beta, perp]))\n",
    "            models.append(lda_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data = [[result[3] for result in results if result[1] == alpha and result[2] == 0.001] for alpha in alphas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "for index, result_set in enumerate(result_data):\n",
    "    plt.plot(n_topics, result_set, label=f'alpha: {alphas[index]}')\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel('number of topics')\n",
    "plt.ylabel('perplexity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = models[47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enbale model visualization\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.gensim.prepare(lda_model, corpus, id2words, mds=\"mmds\", R=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to hold the document topic distributions\n",
    "doc_topic_dists = []\n",
    "for doc in corpus:\n",
    "    topic_dist = lda_model.get_document_topics(doc, minimum_probability=0.0)\n",
    "    doc_topic_dists.append(topic_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of topic distributions into a numpy array\n",
    "doc_topic_matrix = gensim.matutils.corpus2dense(doc_topic_dists, num_terms=lda_model.num_topics).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join document term probablilies with metadata\n",
    "df_result = pd.concat([df.reset_index(drop=True), pd.DataFrame(doc_topic_matrix).reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv('../data/df_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, model in enumerate(models):\n",
    "    lda_model.save(f'../models/lda_grid_{index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora.MmCorpus.serialize('../models/corpus.mm', corpus=corpus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
